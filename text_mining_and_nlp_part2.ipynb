{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Mining and NLP\n",
    "\n",
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Goal**: to internalize the steps, challenges, and methodology of text mining\n",
    "- explore text analysis by hand\n",
    "- apply text mining steps in Jupyter with Python libraries NLTK\n",
    "- classify documents correctly\n",
    "<br/>\n",
    "^ This last step will require modeling!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import string, re\n",
    "import urllib\n",
    "\n",
    "url_a = \"https://raw.githubusercontent.com/aapeebles/text_examples/master/Text%20examples%20folder/A.txt\"\n",
    "url_b = \"https://raw.githubusercontent.com/aapeebles/text_examples/master/Text%20examples%20folder/D.txt\"\n",
    "article_a = urllib.request.urlopen(url_a).read()\n",
    "article_a_st = article_a.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens\n",
    "pattern = \"([a-zA-Z]+(?:'[a-z]+)?)\"\n",
    "arta_tokens_raw = nltk.regexp_tokenize(article_a_st, pattern)\n",
    "\n",
    "# lower case\n",
    "arta_tokens = [i.lower() for i in arta_tokens_raw]\n",
    "\n",
    "# stop words if you get an error here uncommment the next line and run the cell again\n",
    "# nltk.download('stopwords')\n",
    "nltk.corpus.stopwords.words(\"english\")\n",
    "\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "arta_tokens_stopped = [w for w in arta_tokens if not w in stop_words]\n",
    "\n",
    "# stem words\n",
    "stemmer = nltk.SnowballStemmer(\"english\")\n",
    "arta_stemmed = [stemmer.stem(word) for word in arta_tokens_stopped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat w second article\n",
    "article_b = urllib.request.urlopen(url_b).read()\n",
    "article_b_st = article_b.decode(\"utf-8\")\n",
    "artb_tokens_raw = nltk.regexp_tokenize(article_b_st, pattern)\n",
    "artb_tokens = [i.lower() for i in artb_tokens_raw]\n",
    "artb_tokens_stopped = [w for w in artb_tokens if not w in stop_words]\n",
    "artb_stemmed = [stemmer.stem(word) for word in artb_tokens_stopped]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Term Frequency (TF)\n",
    "\n",
    "$\\begin{align}\n",
    " tf_{i,j} = \\dfrac{n_{i,j}}{\\displaystyle \\sum_k n_{i,j} }\n",
    "\\end{align} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverse Document Frequency (IDF)\n",
    "\n",
    "$\\begin{align}\n",
    "idf(w) = \\log \\dfrac{N}{df_t}\n",
    "\\end{align} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF score\n",
    "\n",
    "$ \\begin{align}\n",
    "w_{i,j} = tf_{i,j} \\times \\log \\dfrac{N}{df_i} \\\\\n",
    "tf_{i,j} = \\text{number of occurences of } i \\text{ in} j \\\\\n",
    "df_i = \\text{number of documents containing } i \\\\\n",
    "N = \\text{total number of documents}\n",
    "\\end{align} $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counting from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BNP leader Nick Griffin arrested\\n\\nThe leader of the British National Party has been arrested as part of a police inquiry following the screening of a BBC documentary.\\n\\nA party spokesman said Nick Griffin was arrested on Tuesday morning on suspicion of incitement to commit racial hatred. West Yorkshire police confirmed they had arrested a 45-year-old man from outside their area. BNP founding chairman John Tyndall was arrested on Sunday on the same charge.\\n\\nIn July, the BBC documentary Secret Agent featured covertly-filmed footage of BNP activists. Mr Griffin is the twelfth man to be arrested following the documentary. Nine men from West Yorkshire and another man from Leicester have been arrested and freed on bail. Seven of the men had been held variously in connection with suspected racially aggravated public order offences, conspiracy to commit criminal damage and possession of a firearm. Two men, both from Keighley, were arrested in September on suspicion of conspiracy to commit criminal damage. A 24-year-old man from Leicester was detained on Monday on suspicion of incitement to commit racial hatred. A BNP spokesperson said Mr Tyndall, from Brighton, was arrested following a speech he made in Burnley, Lancashire, and was released on police bail.\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_b_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSet = set(arta_stemmed).union(set(artb_stemmed)) \n",
    "wordDictA = dict.fromkeys(wordSet, 0) \n",
    "wordDictB = dict.fromkeys(wordSet, 0) \n",
    "\n",
    "for word in arta_stemmed: \n",
    "    wordDictA[word]+=1\n",
    "    \n",
    "for word in artb_stemmed: \n",
    "    wordDictB[word]+=1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'favour': 1,\n",
       " 'sunday': 0,\n",
       " 'month': 1,\n",
       " 'screen': 0,\n",
       " 'without': 1,\n",
       " 'chairman': 0,\n",
       " 'poland': 1,\n",
       " 'state': 2,\n",
       " 'brighton': 0,\n",
       " 'bring': 1,\n",
       " 'legal': 3,\n",
       " 'mep': 2,\n",
       " 'old': 0,\n",
       " 'aggrav': 0,\n",
       " 'com': 1,\n",
       " 'eu': 4,\n",
       " 'exampl': 1,\n",
       " 'european': 2,\n",
       " 'lancashir': 0,\n",
       " 'vote': 1,\n",
       " 'effect': 1,\n",
       " 'fear': 1,\n",
       " 'seven': 0,\n",
       " 'direct': 4,\n",
       " 'reject': 1,\n",
       " 'parti': 0,\n",
       " 'method': 1,\n",
       " 'invent': 5,\n",
       " 'abstain': 1,\n",
       " 'comput': 4,\n",
       " 'gain': 1,\n",
       " 'oppon': 1,\n",
       " 'vocal': 1,\n",
       " 'west': 0,\n",
       " 'let': 1,\n",
       " 'leicest': 0,\n",
       " 'achiev': 1,\n",
       " 'largest': 1,\n",
       " 'various': 0,\n",
       " 'racial': 0,\n",
       " 'twelfth': 0,\n",
       " 'court': 1,\n",
       " 'lead': 1,\n",
       " 'conspiraci': 0,\n",
       " 'busi': 1,\n",
       " 'spokesperson': 0,\n",
       " 'men': 0,\n",
       " 'burnley': 0,\n",
       " 'govern': 1,\n",
       " 'action': 1,\n",
       " 'featur': 0,\n",
       " 'submit': 1,\n",
       " 'open': 1,\n",
       " 'intens': 1,\n",
       " 'concern': 1,\n",
       " 'secret': 0,\n",
       " 'freed': 0,\n",
       " 'speech': 0,\n",
       " 'griffin': 0,\n",
       " 'tyndal': 0,\n",
       " 'impact': 1,\n",
       " 'chanc': 1,\n",
       " 'union': 1,\n",
       " 'critic': 2,\n",
       " 'held': 0,\n",
       " 'yorkshir': 0,\n",
       " 'parliament': 2,\n",
       " 'put': 1,\n",
       " 'first': 1,\n",
       " 'morn': 0,\n",
       " 'nine': 0,\n",
       " 'john': 0,\n",
       " 'servic': 1,\n",
       " 'year': 0,\n",
       " 'committe': 2,\n",
       " 'affair': 1,\n",
       " 'hurt': 1,\n",
       " 'happen': 1,\n",
       " 'support': 2,\n",
       " 'protect': 2,\n",
       " 'part': 0,\n",
       " 'adopt': 1,\n",
       " 'suspect': 0,\n",
       " 'member': 2,\n",
       " 'arrest': 0,\n",
       " 'firearm': 0,\n",
       " 'develop': 1,\n",
       " 'confirm': 0,\n",
       " 'setback': 1,\n",
       " 'hold': 1,\n",
       " 'shop': 1,\n",
       " 'start': 1,\n",
       " 'documentari': 0,\n",
       " 'innov': 1,\n",
       " 'bnp': 0,\n",
       " 'permit': 1,\n",
       " 'twice': 1,\n",
       " 'man': 0,\n",
       " 'us': 3,\n",
       " 'amazon': 1,\n",
       " 'compani': 1,\n",
       " 'new': 2,\n",
       " 'polic': 0,\n",
       " 'order': 2,\n",
       " 'rewrit': 1,\n",
       " 'commiss': 1,\n",
       " 'larg': 1,\n",
       " 'bail': 0,\n",
       " 'bbc': 0,\n",
       " 'might': 1,\n",
       " 'back': 2,\n",
       " 'issu': 1,\n",
       " 'welcom': 1,\n",
       " 'say': 3,\n",
       " 'meet': 1,\n",
       " 'spokesman': 0,\n",
       " 'ineffici': 1,\n",
       " 'program': 1,\n",
       " 'base': 2,\n",
       " 'damag': 0,\n",
       " 'charg': 0,\n",
       " 'nation': 1,\n",
       " 'word': 1,\n",
       " 'debat': 1,\n",
       " 'small': 2,\n",
       " 'could': 3,\n",
       " 'serv': 1,\n",
       " 'public': 0,\n",
       " 'outsid': 0,\n",
       " 'two': 2,\n",
       " 'offenc': 0,\n",
       " 'possess': 0,\n",
       " 'internet': 1,\n",
       " 'momentum': 1,\n",
       " 'juli': 0,\n",
       " 'give': 1,\n",
       " 'tuesday': 0,\n",
       " 'use': 1,\n",
       " 'area': 0,\n",
       " 'juri': 2,\n",
       " 'covert': 0,\n",
       " 'would': 3,\n",
       " 'read': 1,\n",
       " 'click': 1,\n",
       " 'play': 1,\n",
       " 'fuller': 1,\n",
       " 'implement': 2,\n",
       " 'activist': 0,\n",
       " 'reboot': 1,\n",
       " 'immens': 1,\n",
       " 'film': 0,\n",
       " 'europ': 1,\n",
       " 'field': 1,\n",
       " 'law': 5,\n",
       " 'rule': 1,\n",
       " 'fight': 1,\n",
       " 'softwar': 3,\n",
       " 'mr': 0,\n",
       " 'british': 0,\n",
       " 'commit': 0,\n",
       " 'footag': 0,\n",
       " 'crimin': 0,\n",
       " 'suffer': 1,\n",
       " 'model': 1,\n",
       " 'larger': 1,\n",
       " 'keighley': 0,\n",
       " 'line': 1,\n",
       " 'offer': 1,\n",
       " 'suspicion': 0,\n",
       " 'releas': 0,\n",
       " 'decis': 1,\n",
       " 'one': 3,\n",
       " 'patent': 5,\n",
       " 'agent': 0,\n",
       " 'lobbi': 1,\n",
       " 'anoth': 0,\n",
       " 'even': 1,\n",
       " 'similar': 1,\n",
       " 'draft': 3,\n",
       " 'sourc': 1,\n",
       " 'leader': 0,\n",
       " 'controversi': 1,\n",
       " 'found': 0,\n",
       " 'follow': 0,\n",
       " 'current': 1,\n",
       " 'fail': 1,\n",
       " 'financi': 1,\n",
       " 'intend': 1,\n",
       " 'nick': 0,\n",
       " 'made': 0,\n",
       " 'inquiri': 0,\n",
       " 'said': 2,\n",
       " 'propos': 2,\n",
       " 'connect': 0,\n",
       " 'implic': 1,\n",
       " 'firm': 2,\n",
       " 'pressur': 1,\n",
       " 'mean': 1,\n",
       " 'monday': 0,\n",
       " 'incit': 0,\n",
       " 'detain': 0,\n",
       " 'hatr': 0,\n",
       " 'septemb': 0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordDictA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'favour': 0,\n",
       " 'sunday': 1,\n",
       " 'month': 0,\n",
       " 'screen': 1,\n",
       " 'without': 0,\n",
       " 'chairman': 1,\n",
       " 'poland': 0,\n",
       " 'state': 0,\n",
       " 'brighton': 1,\n",
       " 'bring': 0,\n",
       " 'legal': 0,\n",
       " 'mep': 0,\n",
       " 'old': 2,\n",
       " 'aggrav': 1,\n",
       " 'com': 0,\n",
       " 'eu': 0,\n",
       " 'exampl': 0,\n",
       " 'european': 0,\n",
       " 'lancashir': 1,\n",
       " 'vote': 0,\n",
       " 'effect': 0,\n",
       " 'fear': 0,\n",
       " 'seven': 1,\n",
       " 'direct': 0,\n",
       " 'reject': 0,\n",
       " 'parti': 2,\n",
       " 'method': 0,\n",
       " 'invent': 0,\n",
       " 'abstain': 0,\n",
       " 'comput': 0,\n",
       " 'gain': 0,\n",
       " 'oppon': 0,\n",
       " 'vocal': 0,\n",
       " 'west': 2,\n",
       " 'let': 0,\n",
       " 'leicest': 2,\n",
       " 'achiev': 0,\n",
       " 'largest': 0,\n",
       " 'various': 1,\n",
       " 'racial': 3,\n",
       " 'twelfth': 1,\n",
       " 'court': 0,\n",
       " 'lead': 0,\n",
       " 'conspiraci': 2,\n",
       " 'busi': 0,\n",
       " 'spokesperson': 1,\n",
       " 'men': 3,\n",
       " 'burnley': 1,\n",
       " 'govern': 0,\n",
       " 'action': 0,\n",
       " 'featur': 1,\n",
       " 'submit': 0,\n",
       " 'open': 0,\n",
       " 'intens': 0,\n",
       " 'concern': 0,\n",
       " 'secret': 1,\n",
       " 'freed': 1,\n",
       " 'speech': 1,\n",
       " 'griffin': 3,\n",
       " 'tyndal': 2,\n",
       " 'impact': 0,\n",
       " 'chanc': 0,\n",
       " 'union': 0,\n",
       " 'critic': 0,\n",
       " 'held': 1,\n",
       " 'yorkshir': 2,\n",
       " 'parliament': 0,\n",
       " 'put': 0,\n",
       " 'first': 0,\n",
       " 'morn': 1,\n",
       " 'nine': 1,\n",
       " 'john': 1,\n",
       " 'servic': 0,\n",
       " 'year': 2,\n",
       " 'committe': 0,\n",
       " 'affair': 0,\n",
       " 'hurt': 0,\n",
       " 'happen': 0,\n",
       " 'support': 0,\n",
       " 'protect': 0,\n",
       " 'part': 1,\n",
       " 'adopt': 0,\n",
       " 'suspect': 1,\n",
       " 'member': 0,\n",
       " 'arrest': 9,\n",
       " 'firearm': 1,\n",
       " 'develop': 0,\n",
       " 'confirm': 1,\n",
       " 'setback': 0,\n",
       " 'hold': 0,\n",
       " 'shop': 0,\n",
       " 'start': 0,\n",
       " 'documentari': 3,\n",
       " 'innov': 0,\n",
       " 'bnp': 4,\n",
       " 'permit': 0,\n",
       " 'twice': 0,\n",
       " 'man': 4,\n",
       " 'us': 0,\n",
       " 'amazon': 0,\n",
       " 'compani': 0,\n",
       " 'new': 0,\n",
       " 'polic': 3,\n",
       " 'order': 1,\n",
       " 'rewrit': 0,\n",
       " 'commiss': 0,\n",
       " 'larg': 0,\n",
       " 'bail': 2,\n",
       " 'bbc': 2,\n",
       " 'might': 0,\n",
       " 'back': 0,\n",
       " 'issu': 0,\n",
       " 'welcom': 0,\n",
       " 'say': 0,\n",
       " 'meet': 0,\n",
       " 'spokesman': 1,\n",
       " 'ineffici': 0,\n",
       " 'program': 0,\n",
       " 'base': 0,\n",
       " 'damag': 2,\n",
       " 'charg': 1,\n",
       " 'nation': 1,\n",
       " 'word': 0,\n",
       " 'debat': 0,\n",
       " 'small': 0,\n",
       " 'could': 0,\n",
       " 'serv': 0,\n",
       " 'public': 1,\n",
       " 'outsid': 1,\n",
       " 'two': 1,\n",
       " 'offenc': 1,\n",
       " 'possess': 1,\n",
       " 'internet': 0,\n",
       " 'momentum': 0,\n",
       " 'juli': 1,\n",
       " 'give': 0,\n",
       " 'tuesday': 1,\n",
       " 'use': 0,\n",
       " 'area': 1,\n",
       " 'juri': 0,\n",
       " 'covert': 1,\n",
       " 'would': 0,\n",
       " 'read': 0,\n",
       " 'click': 0,\n",
       " 'play': 0,\n",
       " 'fuller': 0,\n",
       " 'implement': 0,\n",
       " 'activist': 1,\n",
       " 'reboot': 0,\n",
       " 'immens': 0,\n",
       " 'film': 1,\n",
       " 'europ': 0,\n",
       " 'field': 0,\n",
       " 'law': 0,\n",
       " 'rule': 0,\n",
       " 'fight': 0,\n",
       " 'softwar': 0,\n",
       " 'mr': 2,\n",
       " 'british': 1,\n",
       " 'commit': 4,\n",
       " 'footag': 1,\n",
       " 'crimin': 2,\n",
       " 'suffer': 0,\n",
       " 'model': 0,\n",
       " 'larger': 0,\n",
       " 'keighley': 1,\n",
       " 'line': 0,\n",
       " 'offer': 0,\n",
       " 'suspicion': 3,\n",
       " 'releas': 1,\n",
       " 'decis': 0,\n",
       " 'one': 0,\n",
       " 'patent': 0,\n",
       " 'agent': 1,\n",
       " 'lobbi': 0,\n",
       " 'anoth': 1,\n",
       " 'even': 0,\n",
       " 'similar': 0,\n",
       " 'draft': 0,\n",
       " 'sourc': 0,\n",
       " 'leader': 2,\n",
       " 'controversi': 0,\n",
       " 'found': 1,\n",
       " 'follow': 3,\n",
       " 'current': 0,\n",
       " 'fail': 0,\n",
       " 'financi': 0,\n",
       " 'intend': 0,\n",
       " 'nick': 2,\n",
       " 'made': 1,\n",
       " 'inquiri': 1,\n",
       " 'said': 2,\n",
       " 'propos': 0,\n",
       " 'connect': 1,\n",
       " 'implic': 0,\n",
       " 'firm': 0,\n",
       " 'pressur': 0,\n",
       " 'mean': 0,\n",
       " 'monday': 1,\n",
       " 'incit': 2,\n",
       " 'detain': 1,\n",
       " 'hatr': 2,\n",
       " 'septemb': 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordDictB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstain</th>\n",
       "      <th>achiev</th>\n",
       "      <th>action</th>\n",
       "      <th>activist</th>\n",
       "      <th>adopt</th>\n",
       "      <th>affair</th>\n",
       "      <th>agent</th>\n",
       "      <th>aggrav</th>\n",
       "      <th>amazon</th>\n",
       "      <th>anoth</th>\n",
       "      <th>...</th>\n",
       "      <th>various</th>\n",
       "      <th>vocal</th>\n",
       "      <th>vote</th>\n",
       "      <th>welcom</th>\n",
       "      <th>west</th>\n",
       "      <th>without</th>\n",
       "      <th>word</th>\n",
       "      <th>would</th>\n",
       "      <th>year</th>\n",
       "      <th>yorkshir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 203 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abstain  achiev  action  activist  adopt  affair  agent  aggrav  amazon  \\\n",
       "0        1       1       1         0      1       1      0       0       1   \n",
       "1        0       0       0         1      0       0      1       1       0   \n",
       "\n",
       "   anoth  ...  various  vocal  vote  welcom  west  without  word  would  year  \\\n",
       "0      0  ...        0      1     1       1     0        1     1      3     0   \n",
       "1      1  ...        1      0     0       0     2        0     0      0     2   \n",
       "\n",
       "   yorkshir  \n",
       "0         0  \n",
       "1         2  \n",
       "\n",
       "[2 rows x 203 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([wordDictA, wordDictB], index=range(2))\n",
    "df.reindex(sorted(df.columns), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>24</th>\n",
       "      <th>45</th>\n",
       "      <th>about</th>\n",
       "      <th>abstain</th>\n",
       "      <th>achieve</th>\n",
       "      <th>action</th>\n",
       "      <th>activists</th>\n",
       "      <th>adoption</th>\n",
       "      <th>affairs</th>\n",
       "      <th>after</th>\n",
       "      <th>...</th>\n",
       "      <th>west</th>\n",
       "      <th>when</th>\n",
       "      <th>which</th>\n",
       "      <th>who</th>\n",
       "      <th>with</th>\n",
       "      <th>without</th>\n",
       "      <th>words</th>\n",
       "      <th>would</th>\n",
       "      <th>year</th>\n",
       "      <th>yorkshire</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 261 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   24  45  about  abstain  achieve  action  activists  adoption  affairs  \\\n",
       "0   1   1      0        0        0       0          1         0        0   \n",
       "1   0   0      1        1        1       1          0         1        1   \n",
       "\n",
       "   after  ...  west  when  which  who  with  without  words  would  year  \\\n",
       "0      0  ...     2     0      0    0     1        0      0      0     2   \n",
       "1      1  ...     0     1      1    1     2        1      1      3     0   \n",
       "\n",
       "   yorkshire  \n",
       "0          2  \n",
       "1          0  \n",
       "\n",
       "[2 rows x 261 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = sklearn.feature_extraction.text.CountVectorizer()\n",
    "counts_fitted = counts.fit_transform([article_b_st, article_a_st])\n",
    "\n",
    "pd.DataFrame(counts_fitted.toarray(), columns=counts.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tfidf from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTF(wordDict, bow):\n",
    "    tfDict = {}\n",
    "    bowCount = len(bow)\n",
    "    for word, count in wordDict.items():\n",
    "        tfDict[word] = count / bowCount\n",
    "    return tfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfbowA = computeTF(wordDictA, arta_stemmed)\n",
    "tfbowB = computeTF(wordDictB, artb_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'favour': 0.005434782608695652,\n",
       " 'sunday': 0.0,\n",
       " 'month': 0.005434782608695652,\n",
       " 'screen': 0.0,\n",
       " 'without': 0.005434782608695652,\n",
       " 'chairman': 0.0,\n",
       " 'poland': 0.005434782608695652,\n",
       " 'state': 0.010869565217391304,\n",
       " 'brighton': 0.0,\n",
       " 'bring': 0.005434782608695652,\n",
       " 'legal': 0.016304347826086956,\n",
       " 'mep': 0.010869565217391304,\n",
       " 'old': 0.0,\n",
       " 'aggrav': 0.0,\n",
       " 'com': 0.005434782608695652,\n",
       " 'eu': 0.021739130434782608,\n",
       " 'exampl': 0.005434782608695652,\n",
       " 'european': 0.010869565217391304,\n",
       " 'lancashir': 0.0,\n",
       " 'vote': 0.005434782608695652,\n",
       " 'effect': 0.005434782608695652,\n",
       " 'fear': 0.005434782608695652,\n",
       " 'seven': 0.0,\n",
       " 'direct': 0.021739130434782608,\n",
       " 'reject': 0.005434782608695652,\n",
       " 'parti': 0.0,\n",
       " 'method': 0.005434782608695652,\n",
       " 'invent': 0.02717391304347826,\n",
       " 'abstain': 0.005434782608695652,\n",
       " 'comput': 0.021739130434782608,\n",
       " 'gain': 0.005434782608695652,\n",
       " 'oppon': 0.005434782608695652,\n",
       " 'vocal': 0.005434782608695652,\n",
       " 'west': 0.0,\n",
       " 'let': 0.005434782608695652,\n",
       " 'leicest': 0.0,\n",
       " 'achiev': 0.005434782608695652,\n",
       " 'largest': 0.005434782608695652,\n",
       " 'various': 0.0,\n",
       " 'racial': 0.0,\n",
       " 'twelfth': 0.0,\n",
       " 'court': 0.005434782608695652,\n",
       " 'lead': 0.005434782608695652,\n",
       " 'conspiraci': 0.0,\n",
       " 'busi': 0.005434782608695652,\n",
       " 'spokesperson': 0.0,\n",
       " 'men': 0.0,\n",
       " 'burnley': 0.0,\n",
       " 'govern': 0.005434782608695652,\n",
       " 'action': 0.005434782608695652,\n",
       " 'featur': 0.0,\n",
       " 'submit': 0.005434782608695652,\n",
       " 'open': 0.005434782608695652,\n",
       " 'intens': 0.005434782608695652,\n",
       " 'concern': 0.005434782608695652,\n",
       " 'secret': 0.0,\n",
       " 'freed': 0.0,\n",
       " 'speech': 0.0,\n",
       " 'griffin': 0.0,\n",
       " 'tyndal': 0.0,\n",
       " 'impact': 0.005434782608695652,\n",
       " 'chanc': 0.005434782608695652,\n",
       " 'union': 0.005434782608695652,\n",
       " 'critic': 0.010869565217391304,\n",
       " 'held': 0.0,\n",
       " 'yorkshir': 0.0,\n",
       " 'parliament': 0.010869565217391304,\n",
       " 'put': 0.005434782608695652,\n",
       " 'first': 0.005434782608695652,\n",
       " 'morn': 0.0,\n",
       " 'nine': 0.0,\n",
       " 'john': 0.0,\n",
       " 'servic': 0.005434782608695652,\n",
       " 'year': 0.0,\n",
       " 'committe': 0.010869565217391304,\n",
       " 'affair': 0.005434782608695652,\n",
       " 'hurt': 0.005434782608695652,\n",
       " 'happen': 0.005434782608695652,\n",
       " 'support': 0.010869565217391304,\n",
       " 'protect': 0.010869565217391304,\n",
       " 'part': 0.0,\n",
       " 'adopt': 0.005434782608695652,\n",
       " 'suspect': 0.0,\n",
       " 'member': 0.010869565217391304,\n",
       " 'arrest': 0.0,\n",
       " 'firearm': 0.0,\n",
       " 'develop': 0.005434782608695652,\n",
       " 'confirm': 0.0,\n",
       " 'setback': 0.005434782608695652,\n",
       " 'hold': 0.005434782608695652,\n",
       " 'shop': 0.005434782608695652,\n",
       " 'start': 0.005434782608695652,\n",
       " 'documentari': 0.0,\n",
       " 'innov': 0.005434782608695652,\n",
       " 'bnp': 0.0,\n",
       " 'permit': 0.005434782608695652,\n",
       " 'twice': 0.005434782608695652,\n",
       " 'man': 0.0,\n",
       " 'us': 0.016304347826086956,\n",
       " 'amazon': 0.005434782608695652,\n",
       " 'compani': 0.005434782608695652,\n",
       " 'new': 0.010869565217391304,\n",
       " 'polic': 0.0,\n",
       " 'order': 0.010869565217391304,\n",
       " 'rewrit': 0.005434782608695652,\n",
       " 'commiss': 0.005434782608695652,\n",
       " 'larg': 0.005434782608695652,\n",
       " 'bail': 0.0,\n",
       " 'bbc': 0.0,\n",
       " 'might': 0.005434782608695652,\n",
       " 'back': 0.010869565217391304,\n",
       " 'issu': 0.005434782608695652,\n",
       " 'welcom': 0.005434782608695652,\n",
       " 'say': 0.016304347826086956,\n",
       " 'meet': 0.005434782608695652,\n",
       " 'spokesman': 0.0,\n",
       " 'ineffici': 0.005434782608695652,\n",
       " 'program': 0.005434782608695652,\n",
       " 'base': 0.010869565217391304,\n",
       " 'damag': 0.0,\n",
       " 'charg': 0.0,\n",
       " 'nation': 0.005434782608695652,\n",
       " 'word': 0.005434782608695652,\n",
       " 'debat': 0.005434782608695652,\n",
       " 'small': 0.010869565217391304,\n",
       " 'could': 0.016304347826086956,\n",
       " 'serv': 0.005434782608695652,\n",
       " 'public': 0.0,\n",
       " 'outsid': 0.0,\n",
       " 'two': 0.010869565217391304,\n",
       " 'offenc': 0.0,\n",
       " 'possess': 0.0,\n",
       " 'internet': 0.005434782608695652,\n",
       " 'momentum': 0.005434782608695652,\n",
       " 'juli': 0.0,\n",
       " 'give': 0.005434782608695652,\n",
       " 'tuesday': 0.0,\n",
       " 'use': 0.005434782608695652,\n",
       " 'area': 0.0,\n",
       " 'juri': 0.010869565217391304,\n",
       " 'covert': 0.0,\n",
       " 'would': 0.016304347826086956,\n",
       " 'read': 0.005434782608695652,\n",
       " 'click': 0.005434782608695652,\n",
       " 'play': 0.005434782608695652,\n",
       " 'fuller': 0.005434782608695652,\n",
       " 'implement': 0.010869565217391304,\n",
       " 'activist': 0.0,\n",
       " 'reboot': 0.005434782608695652,\n",
       " 'immens': 0.005434782608695652,\n",
       " 'film': 0.0,\n",
       " 'europ': 0.005434782608695652,\n",
       " 'field': 0.005434782608695652,\n",
       " 'law': 0.02717391304347826,\n",
       " 'rule': 0.005434782608695652,\n",
       " 'fight': 0.005434782608695652,\n",
       " 'softwar': 0.016304347826086956,\n",
       " 'mr': 0.0,\n",
       " 'british': 0.0,\n",
       " 'commit': 0.0,\n",
       " 'footag': 0.0,\n",
       " 'crimin': 0.0,\n",
       " 'suffer': 0.005434782608695652,\n",
       " 'model': 0.005434782608695652,\n",
       " 'larger': 0.005434782608695652,\n",
       " 'keighley': 0.0,\n",
       " 'line': 0.005434782608695652,\n",
       " 'offer': 0.005434782608695652,\n",
       " 'suspicion': 0.0,\n",
       " 'releas': 0.0,\n",
       " 'decis': 0.005434782608695652,\n",
       " 'one': 0.016304347826086956,\n",
       " 'patent': 0.02717391304347826,\n",
       " 'agent': 0.0,\n",
       " 'lobbi': 0.005434782608695652,\n",
       " 'anoth': 0.0,\n",
       " 'even': 0.005434782608695652,\n",
       " 'similar': 0.005434782608695652,\n",
       " 'draft': 0.016304347826086956,\n",
       " 'sourc': 0.005434782608695652,\n",
       " 'leader': 0.0,\n",
       " 'controversi': 0.005434782608695652,\n",
       " 'found': 0.0,\n",
       " 'follow': 0.0,\n",
       " 'current': 0.005434782608695652,\n",
       " 'fail': 0.005434782608695652,\n",
       " 'financi': 0.005434782608695652,\n",
       " 'intend': 0.005434782608695652,\n",
       " 'nick': 0.0,\n",
       " 'made': 0.0,\n",
       " 'inquiri': 0.0,\n",
       " 'said': 0.010869565217391304,\n",
       " 'propos': 0.010869565217391304,\n",
       " 'connect': 0.0,\n",
       " 'implic': 0.005434782608695652,\n",
       " 'firm': 0.010869565217391304,\n",
       " 'pressur': 0.005434782608695652,\n",
       " 'mean': 0.005434782608695652,\n",
       " 'monday': 0.0,\n",
       " 'incit': 0.0,\n",
       " 'detain': 0.0,\n",
       " 'hatr': 0.0,\n",
       " 'septemb': 0.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfbowA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeIDF(docList):\n",
    "    \"\"\" compute inverse doc freq for each doc in the docList\n",
    "    returns: IDF for each doc\n",
    "    \"\"\"\n",
    "    import math\n",
    "    idfDict = {}\n",
    "    N = len(docList)\n",
    "    \n",
    "    idfDict = dict.fromkeys(docList[0].keys(), 0)\n",
    "    for doc in docList:\n",
    "        for word, val in doc.items():\n",
    "            if val > 0:\n",
    "                idfDict[word] += 1\n",
    "    \n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word] = math.log(N / val)\n",
    "        \n",
    "    return idfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfs = computeIDF([wordDictA, wordDictB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'favour': 0.6931471805599453,\n",
       " 'sunday': 0.6931471805599453,\n",
       " 'month': 0.6931471805599453,\n",
       " 'screen': 0.6931471805599453,\n",
       " 'without': 0.6931471805599453,\n",
       " 'chairman': 0.6931471805599453,\n",
       " 'poland': 0.6931471805599453,\n",
       " 'state': 0.6931471805599453,\n",
       " 'brighton': 0.6931471805599453,\n",
       " 'bring': 0.6931471805599453,\n",
       " 'legal': 0.6931471805599453,\n",
       " 'mep': 0.6931471805599453,\n",
       " 'old': 0.6931471805599453,\n",
       " 'aggrav': 0.6931471805599453,\n",
       " 'com': 0.6931471805599453,\n",
       " 'eu': 0.6931471805599453,\n",
       " 'exampl': 0.6931471805599453,\n",
       " 'european': 0.6931471805599453,\n",
       " 'lancashir': 0.6931471805599453,\n",
       " 'vote': 0.6931471805599453,\n",
       " 'effect': 0.6931471805599453,\n",
       " 'fear': 0.6931471805599453,\n",
       " 'seven': 0.6931471805599453,\n",
       " 'direct': 0.6931471805599453,\n",
       " 'reject': 0.6931471805599453,\n",
       " 'parti': 0.6931471805599453,\n",
       " 'method': 0.6931471805599453,\n",
       " 'invent': 0.6931471805599453,\n",
       " 'abstain': 0.6931471805599453,\n",
       " 'comput': 0.6931471805599453,\n",
       " 'gain': 0.6931471805599453,\n",
       " 'oppon': 0.6931471805599453,\n",
       " 'vocal': 0.6931471805599453,\n",
       " 'west': 0.6931471805599453,\n",
       " 'let': 0.6931471805599453,\n",
       " 'leicest': 0.6931471805599453,\n",
       " 'achiev': 0.6931471805599453,\n",
       " 'largest': 0.6931471805599453,\n",
       " 'various': 0.6931471805599453,\n",
       " 'racial': 0.6931471805599453,\n",
       " 'twelfth': 0.6931471805599453,\n",
       " 'court': 0.6931471805599453,\n",
       " 'lead': 0.6931471805599453,\n",
       " 'conspiraci': 0.6931471805599453,\n",
       " 'busi': 0.6931471805599453,\n",
       " 'spokesperson': 0.6931471805599453,\n",
       " 'men': 0.6931471805599453,\n",
       " 'burnley': 0.6931471805599453,\n",
       " 'govern': 0.6931471805599453,\n",
       " 'action': 0.6931471805599453,\n",
       " 'featur': 0.6931471805599453,\n",
       " 'submit': 0.6931471805599453,\n",
       " 'open': 0.6931471805599453,\n",
       " 'intens': 0.6931471805599453,\n",
       " 'concern': 0.6931471805599453,\n",
       " 'secret': 0.6931471805599453,\n",
       " 'freed': 0.6931471805599453,\n",
       " 'speech': 0.6931471805599453,\n",
       " 'griffin': 0.6931471805599453,\n",
       " 'tyndal': 0.6931471805599453,\n",
       " 'impact': 0.6931471805599453,\n",
       " 'chanc': 0.6931471805599453,\n",
       " 'union': 0.6931471805599453,\n",
       " 'critic': 0.6931471805599453,\n",
       " 'held': 0.6931471805599453,\n",
       " 'yorkshir': 0.6931471805599453,\n",
       " 'parliament': 0.6931471805599453,\n",
       " 'put': 0.6931471805599453,\n",
       " 'first': 0.6931471805599453,\n",
       " 'morn': 0.6931471805599453,\n",
       " 'nine': 0.6931471805599453,\n",
       " 'john': 0.6931471805599453,\n",
       " 'servic': 0.6931471805599453,\n",
       " 'year': 0.6931471805599453,\n",
       " 'committe': 0.6931471805599453,\n",
       " 'affair': 0.6931471805599453,\n",
       " 'hurt': 0.6931471805599453,\n",
       " 'happen': 0.6931471805599453,\n",
       " 'support': 0.6931471805599453,\n",
       " 'protect': 0.6931471805599453,\n",
       " 'part': 0.6931471805599453,\n",
       " 'adopt': 0.6931471805599453,\n",
       " 'suspect': 0.6931471805599453,\n",
       " 'member': 0.6931471805599453,\n",
       " 'arrest': 0.6931471805599453,\n",
       " 'firearm': 0.6931471805599453,\n",
       " 'develop': 0.6931471805599453,\n",
       " 'confirm': 0.6931471805599453,\n",
       " 'setback': 0.6931471805599453,\n",
       " 'hold': 0.6931471805599453,\n",
       " 'shop': 0.6931471805599453,\n",
       " 'start': 0.6931471805599453,\n",
       " 'documentari': 0.6931471805599453,\n",
       " 'innov': 0.6931471805599453,\n",
       " 'bnp': 0.6931471805599453,\n",
       " 'permit': 0.6931471805599453,\n",
       " 'twice': 0.6931471805599453,\n",
       " 'man': 0.6931471805599453,\n",
       " 'us': 0.6931471805599453,\n",
       " 'amazon': 0.6931471805599453,\n",
       " 'compani': 0.6931471805599453,\n",
       " 'new': 0.6931471805599453,\n",
       " 'polic': 0.6931471805599453,\n",
       " 'order': 0.0,\n",
       " 'rewrit': 0.6931471805599453,\n",
       " 'commiss': 0.6931471805599453,\n",
       " 'larg': 0.6931471805599453,\n",
       " 'bail': 0.6931471805599453,\n",
       " 'bbc': 0.6931471805599453,\n",
       " 'might': 0.6931471805599453,\n",
       " 'back': 0.6931471805599453,\n",
       " 'issu': 0.6931471805599453,\n",
       " 'welcom': 0.6931471805599453,\n",
       " 'say': 0.6931471805599453,\n",
       " 'meet': 0.6931471805599453,\n",
       " 'spokesman': 0.6931471805599453,\n",
       " 'ineffici': 0.6931471805599453,\n",
       " 'program': 0.6931471805599453,\n",
       " 'base': 0.6931471805599453,\n",
       " 'damag': 0.6931471805599453,\n",
       " 'charg': 0.6931471805599453,\n",
       " 'nation': 0.0,\n",
       " 'word': 0.6931471805599453,\n",
       " 'debat': 0.6931471805599453,\n",
       " 'small': 0.6931471805599453,\n",
       " 'could': 0.6931471805599453,\n",
       " 'serv': 0.6931471805599453,\n",
       " 'public': 0.6931471805599453,\n",
       " 'outsid': 0.6931471805599453,\n",
       " 'two': 0.0,\n",
       " 'offenc': 0.6931471805599453,\n",
       " 'possess': 0.6931471805599453,\n",
       " 'internet': 0.6931471805599453,\n",
       " 'momentum': 0.6931471805599453,\n",
       " 'juli': 0.6931471805599453,\n",
       " 'give': 0.6931471805599453,\n",
       " 'tuesday': 0.6931471805599453,\n",
       " 'use': 0.6931471805599453,\n",
       " 'area': 0.6931471805599453,\n",
       " 'juri': 0.6931471805599453,\n",
       " 'covert': 0.6931471805599453,\n",
       " 'would': 0.6931471805599453,\n",
       " 'read': 0.6931471805599453,\n",
       " 'click': 0.6931471805599453,\n",
       " 'play': 0.6931471805599453,\n",
       " 'fuller': 0.6931471805599453,\n",
       " 'implement': 0.6931471805599453,\n",
       " 'activist': 0.6931471805599453,\n",
       " 'reboot': 0.6931471805599453,\n",
       " 'immens': 0.6931471805599453,\n",
       " 'film': 0.6931471805599453,\n",
       " 'europ': 0.6931471805599453,\n",
       " 'field': 0.6931471805599453,\n",
       " 'law': 0.6931471805599453,\n",
       " 'rule': 0.6931471805599453,\n",
       " 'fight': 0.6931471805599453,\n",
       " 'softwar': 0.6931471805599453,\n",
       " 'mr': 0.6931471805599453,\n",
       " 'british': 0.6931471805599453,\n",
       " 'commit': 0.6931471805599453,\n",
       " 'footag': 0.6931471805599453,\n",
       " 'crimin': 0.6931471805599453,\n",
       " 'suffer': 0.6931471805599453,\n",
       " 'model': 0.6931471805599453,\n",
       " 'larger': 0.6931471805599453,\n",
       " 'keighley': 0.6931471805599453,\n",
       " 'line': 0.6931471805599453,\n",
       " 'offer': 0.6931471805599453,\n",
       " 'suspicion': 0.6931471805599453,\n",
       " 'releas': 0.6931471805599453,\n",
       " 'decis': 0.6931471805599453,\n",
       " 'one': 0.6931471805599453,\n",
       " 'patent': 0.6931471805599453,\n",
       " 'agent': 0.6931471805599453,\n",
       " 'lobbi': 0.6931471805599453,\n",
       " 'anoth': 0.6931471805599453,\n",
       " 'even': 0.6931471805599453,\n",
       " 'similar': 0.6931471805599453,\n",
       " 'draft': 0.6931471805599453,\n",
       " 'sourc': 0.6931471805599453,\n",
       " 'leader': 0.6931471805599453,\n",
       " 'controversi': 0.6931471805599453,\n",
       " 'found': 0.6931471805599453,\n",
       " 'follow': 0.6931471805599453,\n",
       " 'current': 0.6931471805599453,\n",
       " 'fail': 0.6931471805599453,\n",
       " 'financi': 0.6931471805599453,\n",
       " 'intend': 0.6931471805599453,\n",
       " 'nick': 0.6931471805599453,\n",
       " 'made': 0.6931471805599453,\n",
       " 'inquiri': 0.6931471805599453,\n",
       " 'said': 0.0,\n",
       " 'propos': 0.6931471805599453,\n",
       " 'connect': 0.6931471805599453,\n",
       " 'implic': 0.6931471805599453,\n",
       " 'firm': 0.6931471805599453,\n",
       " 'pressur': 0.6931471805599453,\n",
       " 'mean': 0.6931471805599453,\n",
       " 'monday': 0.6931471805599453,\n",
       " 'incit': 0.6931471805599453,\n",
       " 'detain': 0.6931471805599453,\n",
       " 'hatr': 0.6931471805599453,\n",
       " 'septemb': 0.6931471805599453}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTFIDF(tfBow, idfs):\n",
    "    \"\"\"creates function for computing TFIDF\"\"\"\n",
    "    tfidf = {} # creates empty dictionary\n",
    "    for word, val in tfBow.items(): #starts a for loop using keys (word) and values from tfBow\n",
    "        tfidf[word] = val * idfs[word] #for each word in tfBow, the value is multiplied by the idfs for the word. \n",
    "                                        #The word and resulting computation are then added to the dictionary tfidf\n",
    "    return tfidf #returns the dictionary tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfBowA = computeTFIDF(tfbowA, idfs)\n",
    "tfidfBowB = computeTFIDF(tfbowB, idfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstain</th>\n",
       "      <th>achiev</th>\n",
       "      <th>action</th>\n",
       "      <th>activist</th>\n",
       "      <th>adopt</th>\n",
       "      <th>affair</th>\n",
       "      <th>agent</th>\n",
       "      <th>aggrav</th>\n",
       "      <th>amazon</th>\n",
       "      <th>anoth</th>\n",
       "      <th>...</th>\n",
       "      <th>various</th>\n",
       "      <th>vocal</th>\n",
       "      <th>vote</th>\n",
       "      <th>welcom</th>\n",
       "      <th>west</th>\n",
       "      <th>without</th>\n",
       "      <th>word</th>\n",
       "      <th>would</th>\n",
       "      <th>year</th>\n",
       "      <th>yorkshir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003767</td>\n",
       "      <td>0.003767</td>\n",
       "      <td>0.003767</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003767</td>\n",
       "      <td>0.003767</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003767</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003767</td>\n",
       "      <td>0.003767</td>\n",
       "      <td>0.003767</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003767</td>\n",
       "      <td>0.003767</td>\n",
       "      <td>0.011301</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005373</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005373</td>\n",
       "      <td>0.005373</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005373</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005373</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010746</td>\n",
       "      <td>0.010746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 203 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    abstain    achiev    action  activist     adopt    affair     agent  \\\n",
       "0  0.003767  0.003767  0.003767  0.000000  0.003767  0.003767  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.005373  0.000000  0.000000  0.005373   \n",
       "\n",
       "     aggrav    amazon     anoth  ...   various     vocal      vote    welcom  \\\n",
       "0  0.000000  0.003767  0.000000  ...  0.000000  0.003767  0.003767  0.003767   \n",
       "1  0.005373  0.000000  0.005373  ...  0.005373  0.000000  0.000000  0.000000   \n",
       "\n",
       "       west   without      word     would      year  yorkshir  \n",
       "0  0.000000  0.003767  0.003767  0.011301  0.000000  0.000000  \n",
       "1  0.010746  0.000000  0.000000  0.000000  0.010746  0.010746  \n",
       "\n",
       "[2 rows x 203 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "nlpbh = pd.DataFrame([tfidfBowA, tfidfBowB])\n",
    "nlpbh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with sklearn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>''</th>\n",
       "      <th>(</th>\n",
       "      <th>)</th>\n",
       "      <th>,</th>\n",
       "      <th>.</th>\n",
       "      <th>24-year-old</th>\n",
       "      <th>45-year-old</th>\n",
       "      <th>``</th>\n",
       "      <th>abstain</th>\n",
       "      <th>achiev</th>\n",
       "      <th>...</th>\n",
       "      <th>union</th>\n",
       "      <th>us-bas</th>\n",
       "      <th>use</th>\n",
       "      <th>various</th>\n",
       "      <th>vocal</th>\n",
       "      <th>vote</th>\n",
       "      <th>welcom</th>\n",
       "      <th>west</th>\n",
       "      <th>word</th>\n",
       "      <th>yorkshir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.286874</td>\n",
       "      <td>0.394452</td>\n",
       "      <td>0.050399</td>\n",
       "      <td>0.050399</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050399</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100798</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.093784</td>\n",
       "      <td>0.046892</td>\n",
       "      <td>0.046892</td>\n",
       "      <td>0.300275</td>\n",
       "      <td>0.467094</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.093784</td>\n",
       "      <td>0.046892</td>\n",
       "      <td>0.046892</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046892</td>\n",
       "      <td>0.046892</td>\n",
       "      <td>0.046892</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046892</td>\n",
       "      <td>0.046892</td>\n",
       "      <td>0.046892</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046892</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 193 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ''         (         )         ,         .  24-year-old  45-year-old  \\\n",
       "0  0.000000  0.000000  0.000000  0.286874  0.394452     0.050399     0.050399   \n",
       "1  0.093784  0.046892  0.046892  0.300275  0.467094     0.000000     0.000000   \n",
       "\n",
       "         ``   abstain    achiev  ...     union    us-bas       use   various  \\\n",
       "0  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.050399   \n",
       "1  0.093784  0.046892  0.046892  ...  0.046892  0.046892  0.046892  0.000000   \n",
       "\n",
       "      vocal      vote    welcom      west      word  yorkshir  \n",
       "0  0.000000  0.000000  0.000000  0.100798  0.000000  0.100798  \n",
       "1  0.046892  0.046892  0.046892  0.000000  0.046892  0.000000  \n",
       "\n",
       "[2 rows x 193 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stemmer = nltk.SnowballStemmer(\"english\")\n",
    "    stems = []\n",
    "    for item in tokens:\n",
    "        stems.append(stemmer.stem(item))\n",
    "    return stems\n",
    "\n",
    "tfidf = sklearn.feature_extraction.text.TfidfVectorizer(stop_words='english', tokenizer=tokenize)\n",
    "\n",
    "response = tfidf.fit_transform([article_b_st, article_a_st])\n",
    "\n",
    "nlpskl = pd.DataFrame(response.toarray(), columns=tfidf.get_feature_names())\n",
    "nlpskl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note that these values are different! Sklearn's formula for tf-idf is a little more sophisticated than ours. See the doc for the transformer [here](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-grams\n",
    "\n",
    "Notice that the `TfidfVectorizer()` has a parameter called \"ngram_range\". Sometimes we want to search not only for individual words but for pairs or triples (etc.) of words. Using $N$ as a variable for the size of the word cluster to consider, we speak of \"N-grams\". Notice that our default is (1, 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.       , 0.2787621],\n",
       "       [0.2787621, 1.       ]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.pairwise.cosine_similarity(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Modeling\n",
    "\n",
    "Naive Bayes models lend themselves well to NLP problems. Consider the task of trying to predict genre from text. My subjective probability that a text belongs to a certain genre would be a function of the words in the text. So e.g. the (prior) probability that a text is science-fiction may be relatively small. But the probability that a text is science-fiction *given that it uses the word 'cyclotron'* may be quite high.\n",
    "\n",
    "Now: What's \"naive\" about Naive Bayes models?\n",
    "\n",
    "The calculation of the relevant probabilities could get very complicated. But they get much simpler with the (relatively implausible!) assumption that the different features (occurrences of particular words, in our present case of NLP) are *independent*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_20newsgroups().target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = fetch_20newsgroups(subset='train')\n",
    "test = fetch_20newsgroups(subset='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = CountVectorizer(stop_words='english', tokenizer=tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = count.fit_transform(train.data)\n",
    "X_test = count.transform(test.data)\n",
    "y_train = train.target\n",
    "y_test = test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which NB model do you want? Check out the options and their differences [here](https://scikit-learn.org/stable/modules/naive_bayes.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "nb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, nb.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus Statistics \n",
    "\n",
    "How many non-zero elements are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "https://www.gutenberg.org/ebooks/7849.txt.utf-8\n",
    "newval = np.array(df)\n",
    "\n",
    "non_zero_vals = np.count_nonzero(newval) / float(df.shape[0])\n",
    "print(f'Average Number of Non-Zero Elements in Vectorized Articles: {non_zero_vals}')\n",
    "\n",
    "percent_sparse = len([col for col in df.columns if sum(df[col]) <= 1]) / df.shape[1]\n",
    "print(f'Percentage of columns containing 0: {percent_sparse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps:\n",
    "- Create the tf-idf for the **whole** corpus of 12 articles\n",
    "- What are _on average_ the most important words in the whole corpus?\n",
    "- Add a column named \"Target\" to the dataset\n",
    "- Target will be set to 1 or 0 if the article is \"Politics\" or \"Not Politics\"\n",
    "- Do some exploratory analysis of the dataset\n",
    " - What are the average most important words for the \"Politics\" articles?\n",
    " - What are the average most important words for the \"Not Politics\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets talk classification\n",
    "- How would you split into train and test? what would be the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample code\n",
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import nltk\n",
    "import requests\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Frankenstein and Metamorphosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "frankenstein = requests.get('https://www.gutenberg.org/files/84/84-0.txt')\n",
    "frankenstein.encoding ='utf-8'\n",
    "frankenstein = frankenstein.text\n",
    "\n",
    "metamorphosis = requests.get('https://www.gutenberg.org/ebooks/5200.txt.utf-8')\n",
    "metamorphosis.encoding ='utf-8'\n",
    "metamorphosis = metamorphosis.text\n",
    "\n",
    "trial = requests.get('https://www.gutenberg.org/ebooks/7849.txt.utf-8')\n",
    "trial.encoding ='utf-8'\n",
    "trial = trial.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove some extraneous characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "frank = (frankenstein\n",
    "         .replace('\\r', '')\n",
    "         .replace('\\n', ' ')\n",
    "         .strip()[1000:]\n",
    "         .split()\n",
    "        )\n",
    "\n",
    "meta = (metamorphosis\n",
    "        .replace('\\r', '')\n",
    "        .replace('\\n', ' ')\n",
    "        .strip()[1000:]\n",
    "        .split()\n",
    "       )\n",
    "\n",
    "tri = (trial\n",
    "        .replace('\\r', '')\n",
    "        .replace('\\n', ' ')\n",
    "        .strip()[1000:]\n",
    "        .split()\n",
    "       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create our dataset by making our observations random subsets from each book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_sample(book, sample_length=10):\n",
    "    start = randint(0, len(meta) - sample_length)\n",
    "    end = start + sample_length\n",
    "\n",
    "    return ' '.join(book[start:end])\n",
    "\n",
    "n_samples = 100\n",
    "all_text = []\n",
    "\n",
    "all_text.extend([{'text': text_sample(tri), 'label': 'The Trial'} for _ in range(n_samples)])\n",
    "all_text.extend([{'text': text_sample(meta), 'label': 'Metamorphosis'} for _ in range(n_samples)])\n",
    "\n",
    "data = pd.DataFrame(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neglectful with him or especially indifferent, and he decided to'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(1)['text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data['text'], data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = CountVectorizer()\n",
    "\n",
    "X_train_vec = c.fit_transform(X_train)\n",
    "X_test_vec = c.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb = MultinomialNB()\n",
    "\n",
    "nb.fit(X_train_vec, y_train)\n",
    "\n",
    "nb.score(X_test_vec, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
